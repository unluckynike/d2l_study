{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee2bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35cbb275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]),\n",
       " torch.Size([2, 2]),\n",
       " 3,\n",
       " 3,\n",
       " tensor([[19., 25.],\n",
       "         [37., 43.]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过在图像边界周围填充零来保证有足够的空间移动卷积核，从而保持输出大小不变。\n",
    "# 在corr2d函数中实现如上过程，该函数接受输入张量X和卷积核张量K，并返回输出张量Y。\n",
    "\n",
    "def corr2d(X, K):  #@save\n",
    "    \"\"\"计算二维互相关运算\"\"\"\n",
    "    h, w = K.shape # h=2 w=2\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)) # 3-2+1.  3-2+1\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "#             print(X[i:i + h, j:j + w])\n",
    "#             print(X[i:i + h, j:j + w] * K)\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "X.shape, K.shape, X.shape[0],X.shape[1], corr2d(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59583b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积层\n",
    "# 定义的corr2d函数实现二维卷积层。在__init__构造函数中，将weight和bias声明为两个模型参数。\n",
    "# 前向传播函数调用corr2d函数并添加偏置。\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self,kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight=nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias=nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return corr2d(x,self.weight)+self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f904c2",
   "metadata": {},
   "source": [
    "- 无论是左边还是右边逗号都要靠近冒号：\n",
    "- 如果冒号：的左边或者右边还有冒号，这时候就说明其中一个冒号代表的是范围（eg:1:5 从１到４）\n",
    "- 如果冒号：左边或者右边没有任何东西，那么这时候代表全体\n",
    "- [a:b] 对ａ的改变是行的改变，对ｂ的改变是队列的改变\n",
    "- 负数在左侧，则从后往前数n个\n",
    "- 负数在右侧，则是排除了后n个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9458e167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5],\n",
       "        [ 6,  7],\n",
       "        [ 8,  9],\n",
       "        [10, 11],\n",
       "        [12, 13],\n",
       "        [14, 15],\n",
       "        [16, 17],\n",
       "        [18, 19]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取法\n",
    "x=torch.tensor([[0,1],[2,3],[4,5],[6,7],[8,9],[10,11],[12,13],[14,15],[16,17],[18,19]])  \n",
    "x\n",
    "\n",
    "# x[:,0] #　二维数组取第１维所有数据\n",
    "# x[:,1] # 第２列\n",
    "# x[0,:] # 第１行\n",
    "# x[3,:] # 第4行\n",
    "# x[1:4,:] # 第一二三行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab27b258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.ones(6,8)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47c42aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,2:6]=0 # 第一维全取（行） 第二维取2到6列\n",
    "X\n",
    "# 中间四列为黑色（0），其余像素为白色（1）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f12e3e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1., -1.]]),\n",
       " tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造一个高度为1、宽度为2的卷积核K\n",
    "K=torch.tensor([[1.0,-1.0]])\n",
    "Y=corr2d(X,K)\n",
    "K , Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7da6dcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将输入的二维图像转置，再进行如上的互相关运算。 其输出如下，之前检测到的垂直边缘消失了。 \n",
    "# 这个卷积核K只可以检测垂直边缘，无法检测水平边缘。\n",
    "\n",
    "corr2d(X.t(),K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "469758a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,loss28.011\n",
      "epoch:1,loss13.731\n",
      "epoch:2,loss7.069\n",
      "epoch:3,loss3.820\n",
      "epoch:4,loss2.157\n",
      "epoch:5,loss1.262\n",
      "epoch:6,loss0.759\n",
      "epoch:7,loss0.466\n",
      "epoch:8,loss0.290\n",
      "epoch:9,loss0.182\n"
     ]
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(1,1,kernel_size=(1,2),bias=False)\n",
    "\n",
    "X=X.reshape((1,1,6,8))\n",
    "Y=Y.reshape((1,1,6,7))\n",
    "\n",
    "lr=3e-2\n",
    "\n",
    "for i in range(10):\n",
    "    y_hat=conv2d(X)\n",
    "    loss=(y_hat-Y)**2\n",
    "    conv2d.zero_grad()\n",
    "    loss.sum().backward()\n",
    "    # 迭代卷积核\n",
    "    conv2d.weight.data[:]-=lr*conv2d.weight.grad\n",
    "    \n",
    "    print(f'epoch:{i},loss{loss.sum():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d80d7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.9424, -1.0292]]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909af35b",
   "metadata": {},
   "source": [
    "- 二维卷积层的核心计算是二维互相关运算。最简单的形式是，对二维输入数据和卷积核执行互相关操作，然后添加一个偏置。\n",
    "\n",
    "- 我们可以设计一个卷积核来检测图像的边缘。\n",
    "\n",
    "- 我们可以从数据中学习卷积核的参数。\n",
    "\n",
    "- 学习卷积核时，无论用严格卷积运算或互相关运算，卷积层的输出不会受太大影响。\n",
    "\n",
    "- 当需要检测输入特征中更广区域时，我们可以构建一个更深的卷积网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89940525",
   "metadata": {},
   "source": [
    "#### 6.3填充和步幅\n",
    "- 填充：由于我们通常使用小卷积核，因此对于任何单个卷积，我们可能只会丢失几个像素。 但随着我们应用许多连续卷积层，累积丢失的像素数就多了。 解决这个问题的简单方法即为填充（padding）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0d67482f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为了方便起见，我们定义了一个计算卷积层的函数。\n",
    "# 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # 这里的（1，1）表示批量大小和通道数都是1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # 省略前两个维度：批量大小和通道\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "\n",
    "# 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "06bf3beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当卷积核的高度和宽度不同时，我们可以填充不同的高度和宽度，使输出和输入具有相同的高度和宽度。\n",
    "# 使用高度为5，宽度为3的卷积核，高度和宽度两边的填充分别为2和1。\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1)) # 1,1 是in 和 out 的通道数 RGB为3\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4155fefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 步幅 为2\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b6c27174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b3e5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cd8807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53177cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a4b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d7cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e31bb68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345751c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
